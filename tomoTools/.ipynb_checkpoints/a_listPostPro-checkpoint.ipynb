{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3406a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "781d037d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Close all widgets\n",
    "import ipywidgets\n",
    "ipywidgets.Widget.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "232417ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Documents/PhD/tomoTools_als832/tomoTools\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'CtAlgorithm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-85acf627489e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwrapper_ASTRA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscripts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Documents/PhD/tomoTools_als832/tomoTools/wrapper_ASTRA.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphology\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# from tiff_stack import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mCtAlgorithm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# from stripe_artifact_removal import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'CtAlgorithm'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import gc # Garbage collected\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import time\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename, askopenfilenames\n",
    "import torch\n",
    "\n",
    "this_path = os.getcwd()\n",
    "print(this_path)\n",
    "# script_path = this_path+'/../../'\n",
    "script_path = this_path+'/'\n",
    "\n",
    "# script_path = '/home/mihme/Desktop/Github/PhD/Python/'\n",
    "script_path = '/home/ihme/eboigne/PhD/Python/'\n",
    "# script_path = '/Documents/PhD/PhD/Python/'\n",
    "\n",
    "sys.path.append(script_path)\n",
    "sys.path.append(script_path+'utils/')\n",
    "sys.path.append(script_path+'io/')\n",
    "sys.path.append(script_path+'als/')\n",
    "sys.path.append(script_path+'als/b_commandLineALSscripts_andRelated_before2021/')\n",
    "sys.path.append(script_path+'als/d_notebookScripts_2021/')\n",
    "\n",
    "# import plot_tools as pt\n",
    "from rigidTransform3D import *\n",
    "# from manipulateALSdata import maskSolidWithBorder\n",
    "import h5py\n",
    "import File\n",
    "\n",
    "import wrapper_ASTRA\n",
    "\n",
    "from scripts import *\n",
    "from pre_processing_and_reconstruction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10785142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML 1056\n",
      "Tk 1056\n"
     ]
    }
   ],
   "source": [
    "# Check memory usage\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "out = sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for x, size in out:\n",
    "    if size > 1024:\n",
    "        print(x, size) # Size is in bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c996528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1470a344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(torch._C._cuda_getDeviceCount())\n",
    "print(torch.cuda.current_device())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7d524e",
   "metadata": {},
   "source": [
    "# 0. Local functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ebccd67",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def image_angles(h5py_file):\n",
    "    img_angles = []\n",
    "    meta = h5py_file['defaults']['group_attrs']['metadata']\n",
    "    for img_str in meta:\n",
    "        img_angles.append(meta[img_str]['rot_angle'].value)\n",
    "    img_angles = np.sort(np.array(img_angles).astype('float32'))\n",
    "    return(img_angles[img_angles>0])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c3b1aa",
   "metadata": {},
   "source": [
    "# 1. Read and export transmission & sinogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9f3057",
   "metadata": {},
   "source": [
    "## Procedure (For new setup, new COR):\n",
    "- Set path_save\n",
    "- Run cell and pick .h5 file\n",
    "- With ind_last_angle = 0, and boolean_use_COR = False, run cell once. Then tune COR.\n",
    "- Re-run cell again with boolean_use_COR = True, and ind_last_angle = 0. Divide PMDOF_DN in Fiji and divide by \"flippedFirstAngle_COR\": adjust ind_last_angle (should not use mirrored)\n",
    "- Change suffix. Re-run cell with adjusted COR and ind_last_angle.\n",
    "- Check that FBP and FBP flipped look similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0db59c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_save = '/home/mihme/Desktop/data-raw/'\n",
    "# path_save = '/run/media/eboigne/Data1_EB/als/2106/run24/'\n",
    "path_save = '/home/ihme/eboigne/als2106/run12/'\n",
    "# path_save = ''\n",
    "\n",
    "# Hardcoding to import .tif stacks\n",
    "# h5py_file.path_folder = ''\n",
    "# h5py_file.file_name_noExtension = 'run125'\n",
    "# flat = File.File('/run/media/eboigne/Data2_EB/als/1903_shift2_day3/run125_before_flat').readAll()\n",
    "# dark = File.File('/run/media/eboigne/Data2_EB/als/1903_shift2_day3/run127_after_dark').readAll()\n",
    "# proj = File.File('/run/media/eboigne/Data2_EB/als/1903_shift2_day3/run125').readAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06aa4f55",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_h5_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b653a9e95141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0muse_dark_from_scan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_dark_from_scan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mh5py_file_dark\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mread_h5_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'read_h5_file' is not defined"
     ]
    }
   ],
   "source": [
    "# Choose dark\n",
    "use_dark_from_scan = False\n",
    "if not use_dark_from_scan:\n",
    "    h5py_file_dark  = read_h5_file(path_save)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f111d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose flat file\n",
    "use_flat_from_scan = True\n",
    "if not use_flat_from_scan:\n",
    "    h5py_file_flat = read_h5_file(path_save)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "09c52bf7",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using file: /home/ihme/eboigne/als2106/run12/20210618_164335_run12_L2_1x_F_noFlow01_x00y02.h5\n",
      "\t- 2 dark fields\n",
      "\t- 150 white fields\n",
      "\t- 2625 projections\n",
      "\t- Image size: (560, 2560)\n"
     ]
    }
   ],
   "source": [
    "# Choose proj file\n",
    "\n",
    "h5py_files = read_h5_file(path_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811e1597",
   "metadata": {},
   "source": [
    "# Angles\n",
    "\n",
    "With 1x lens, each 0-180 rotation is 5249 angles. With 4x averaging, only 2625 images are saved. The first 2624 images are 4x averaged, while the last one (#2625) is not. This last angle is acquired at the angle theta = 360, and thus should be discarded. With 0-180 modes, only (5249*2-1) = 10,497 images are acquired. (Note 10,497/4 = 2624.25, thus makes sense).\n",
    "\n",
    "The angle value saved in the metadata is the one of the last of the 4 successive angles that were averaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cec53deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tImporting dark -- Done\n",
      "\tBinning dark data .. Done\n",
      "Processing file: /home/ihme/eboigne/als2106/run12/20210618_164335_run12_L2_1x_F_noFlow01_x00y02.h5\n",
      "\tImporting flat -- Done\n",
      "\tImporting projections -- Done\n",
      "\tBinning data ........ Done\n",
      "\tRemoving outliers (zingers) for flats  Done\n",
      "\tRemoving outliers (zingers) for proj ........ Done\n",
      "\tComputing transmission -- Done\n",
      "\tSkipping double normalization\n",
      "\tWriting PMDOF_DN to tif -- Done\n",
      "\tMaking sinograms -- Done\n",
      "This took 74.04619002342224 s\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "boolean_use_COR = 0 # skip FBP reconstruction and any operations using the COR\n",
    "bin_factor = 2\n",
    "COR = 2.14 / bin_factor # [Pixel]\n",
    "# COR = -7.0 * 2 / bin_factor # [Pixel]\n",
    "filter_type = 'ram-lak' # Note from ram-lak, apply Gaussian blur with radius sigma = 1 yields results really close to Parzen.\n",
    "skip_every_slice = 1 # For FBP reconstruction\n",
    "\n",
    "# ======================================== #\n",
    "\n",
    "bool_1x = True\n",
    "added_suffix = '' # '_skipPixel_2h' # Start with '_'. No '_' at end. Eg: '_indLastAngle2'.\n",
    "\n",
    "# Angles info \n",
    "if bool_1x:\n",
    "    pixel_size_microns = 9.25 # [microns]\n",
    "    height = 520\n",
    "    N_avg = 4\n",
    "    N_angles_per_half_circle = 1313 # Note that the last angle is the same as the first.\n",
    "    boolean_use_DN = False # True\n",
    "else:\n",
    "    pixel_size_microns = 1.304 # [microns]\n",
    "    height = 2160\n",
    "    N_avg = 1\n",
    "    N_angles_per_half_circle = 985 # Note that the last angle is the same as the first.\n",
    "    boolean_use_DN = False\n",
    "\n",
    "angles_all = np.linspace(0, 2*np.pi, 2*(N_angles_per_half_circle*N_avg-(N_avg-1))-1)\n",
    "angles_reconstructed_to_match_metadata = np.concatenate((angles_all[N_avg-1::N_avg], [360]))\n",
    "# print(np.sum((angles_reconstructed_to_match_metadata - img_angles)>1e-4))\n",
    "ones = np.ones([N_avg,]) / (1.0*N_avg)\n",
    "angles_to_use = np.convolve(angles_all, ones, mode = 'same')[2::4]\n",
    "\n",
    "angles_to_use1 = angles_to_use[:N_angles_per_half_circle-1]\n",
    "angles_to_use2 = angles_to_use[N_angles_per_half_circle-1:]\n",
    "\n",
    "N_half_circles = 2 # With half-circles, and 0-180 range: the 180 angle is repeated (acquired twice)\n",
    "boolean_0_180_range = False\n",
    "\n",
    "# Use less data for testing\n",
    "boolean_testing = False\n",
    "testing_skip_angle = 1\n",
    "testing_skip_pixel = 1\n",
    "testing_multiply_chunks = 1\n",
    "\n",
    "# Bining\n",
    "bin_factor_angle = 1\n",
    "bin_gpu_chunk_size = 2*114*bin_factor * bin_factor -2 # 456: Uses ~4GB GPU RAM.\n",
    "# bin_gpu_chunk_size = 37*3-2 #\n",
    "# bin_gpu_chunk_size = 451//8+5 #\n",
    "\n",
    "# Double normalization\n",
    "boolean_use_DN_row_by_row = False\n",
    "boolean_use_TN = False # True\n",
    "window_width_DN = 25 // bin_factor // testing_skip_pixel # Accounts for bin_factor\n",
    "window_cutEdge_DN = 10 // bin_factor // testing_skip_pixel # Accounts for bin_factor\n",
    "ind_range_DN = np.concatenate((np.arange(window_cutEdge_DN, window_width_DN,1),np.arange(2560//bin_factor//testing_skip_pixel-(window_width_DN),2560//bin_factor//testing_skip_pixel-window_cutEdge_DN,1)))\n",
    "\n",
    "# Outlier correction\n",
    "use_outlier_correction = True\n",
    "gpu_median_filter_chunk_size = 4*27*bin_factor*bin_factor-3 # Avoid divider of Nangles and Nflats. Even smaller because median filter requires large memory use. Check nvidia-smi\n",
    "outlier_kernel_half_width = 2 # Make it at least bin_factor, otherwise can miss zinglers on first/last slices\n",
    "outlier_zinger_threshold = 0.3\n",
    "\n",
    "# Reconstruction\n",
    "\n",
    "boolean_skip_non_COR = 0# boolean_use_COR\n",
    "# boolean_skip_non_COR = False\n",
    "ind_last_angle = 1 # Counting backwards. 0: using all angles, 1: Skip last angle, ...\n",
    "added_suffix = added_suffix+'_indLastAngle'+str(ind_last_angle)\n",
    "\n",
    "# Saving proj and sino. (1313 = 101 * 13)\n",
    "proj_save_every = 31\n",
    "sino_save_every = 1 # Don't forget bin_factor\n",
    "ind_save_PMDOF_DN = np.concatenate((np.arange(0, (N_angles_per_half_circle-ind_last_angle)//bin_factor_angle, proj_save_every), np.arange((N_angles_per_half_circle-ind_last_angle)//bin_factor_angle-4,(N_angles_per_half_circle-ind_last_angle)//bin_factor_angle,1))).astype('int')\n",
    "ind_save_sinogram = np.arange(0, 2200//bin_factor, sino_save_every).astype('int') # 700 supposed to be #pixels vertically. Over-estimated, and later cropping table.\n",
    "save_sinogram = False\n",
    "\n",
    "# ======================================== #\n",
    "\n",
    "# Run\n",
    "pixel_size_cm = pixel_size_microns / 1.0e4 * bin_factor\n",
    "\n",
    "if not boolean_skip_non_COR:\n",
    "\n",
    "    if boolean_testing:\n",
    "        bin_gpu_chunk_size *= testing_multiply_chunks\n",
    "        gpu_median_filter_chunk_size *= testing_multiply_chunks\n",
    "        N_angles_per_half_circle = N_angles_per_half_circle // testing_skip_angle \n",
    "        window_width_DN = window_width_DN // testing_skip_pixel\n",
    "        ind_save_PMDOF_DN = np.concatenate((np.arange(0, (N_angles_per_half_circle-ind_last_angle)//bin_factor_angle, proj_save_every), np.arange((N_angles_per_half_circle-ind_last_angle)//bin_factor_angle-4,(N_angles_per_half_circle-ind_last_angle)//bin_factor_angle,1))).astype('int')\n",
    "        ind_save_sinogram = ind_save_sinogram[::testing_skip_pixel] // testing_skip_pixel\n",
    "        COR /= testing_skip_pixel\n",
    "        pixel_size_cm /= testing_skip_pixel\n",
    "\n",
    "    print2('\\tImporting dark -- ',end='')\n",
    "    if use_dark_from_scan:\n",
    "        dark = np.array(h5py_file['exchange']['data_dark']).astype('float32')\n",
    "    else:\n",
    "        dark = np.array(h5py_file_dark['exchange']['data']).astype('float32')\n",
    "    print2('Done')\n",
    "\n",
    "#     if bool_1x:\n",
    "#         offset = int((2160-height)/2)\n",
    "#         dark = dark[:,offset:-offset,:]\n",
    "\n",
    "    if boolean_testing:\n",
    "        dark = dark[::testing_skip_angle, ::testing_skip_pixel, ::testing_skip_pixel]\n",
    "\n",
    "    if bin_factor>1:\n",
    "        print2('\\tBinning dark data ',end='')\n",
    "        dark = fast_pytorch_bin_chunk(dark,bin_factor, chunk_size = bin_gpu_chunk_size)\n",
    "        print2(' Done')\n",
    "    dark_avg = np.mean(dark,axis = 0)\n",
    "    ind_save_sinogram = ind_save_sinogram[ind_save_sinogram < dark.shape[1]]\n",
    "\n",
    "\n",
    "\n",
    "for h5py_file in h5py_files:\n",
    "    tic = time.time()\n",
    "    print2('Processing file: '+str(h5py_file.path_file))\n",
    "    if not boolean_skip_non_COR:\n",
    "        print2('\\tImporting flat -- ',end='')\n",
    "        if use_flat_from_scan:\n",
    "            flat = h5py_file['exchange']['data_white']\n",
    "        else:\n",
    "            flat = h5py_file_flat['exchange']['data']\n",
    "        print2('Done')\n",
    "\n",
    "        if bool_1x:\n",
    "            flat = flat[-100:]\n",
    "\n",
    "        if boolean_testing:\n",
    "            flat = flat[::testing_skip_angle, ::testing_skip_pixel, ::testing_skip_pixel]\n",
    "\n",
    "        print2('\\tImporting projections -- ',end='')\n",
    "        proj = h5py_file['exchange']['data']\n",
    "        if N_avg == 1:\n",
    "            proj = np.concatenate((proj[:-3], np.reshape(proj[-1,:,:],[1, 2160,2560])))\n",
    "        print2('Done')\n",
    "\n",
    "        if boolean_testing:\n",
    "            proj = proj[::testing_skip_angle, ::testing_skip_pixel, ::testing_skip_pixel]\n",
    "\n",
    "        bin_str = str(bin_factor_angle)+'x'+str(bin_factor)+'x'+str(bin_factor)\n",
    "        if bin_factor>1:\n",
    "            print2('\\tBinning data ',end='')\n",
    "            flat = fast_pytorch_bin_chunk(flat,bin_factor, chunk_size = bin_gpu_chunk_size)\n",
    "            if N_half_circles == 1:\n",
    "                if ind_last_angle > 0:\n",
    "                    proj = proj[:-ind_last_angle]\n",
    "                proj = fast_pytorch_bin_chunk(proj,bin_factor, bin_factor_angle = bin_factor_angle, chunk_size = bin_gpu_chunk_size)\n",
    "            elif N_half_circles == 2:\n",
    "                if ind_last_angle > 0:\n",
    "                    proj1 = fast_pytorch_bin_chunk(proj[:N_angles_per_half_circle-1],bin_factor, bin_factor_angle = bin_factor_angle, chunk_size = bin_gpu_chunk_size)\n",
    "                    proj2 = fast_pytorch_bin_chunk(proj[N_angles_per_half_circle-1:-ind_last_angle],bin_factor, bin_factor_angle = bin_factor_angle, chunk_size = bin_gpu_chunk_size)\n",
    "                else:\n",
    "                    proj1 = fast_pytorch_bin_chunk(proj[:N_angles_per_half_circle-1],bin_factor, bin_factor_angle = bin_factor_angle, chunk_size = bin_gpu_chunk_size)\n",
    "                    proj2 = fast_pytorch_bin_chunk(proj[N_angles_per_half_circle-1:],bin_factor, bin_factor_angle = bin_factor_angle, chunk_size = bin_gpu_chunk_size)\n",
    "            print2(' Done')\n",
    "            ind_save_PMDOF_DN = ind_save_PMDOF_DN[ind_save_PMDOF_DN<proj2.shape[0]]\n",
    "        else:\n",
    "            if N_half_circles == 2:\n",
    "                if ind_last_angle > 0:\n",
    "                    proj1 = proj[:N_angles_per_half_circle-1]\n",
    "                    proj2 = proj[N_angles_per_half_circle-1:-ind_last_angle]\n",
    "                else:\n",
    "                    proj1 = proj[:N_angles_per_half_circle-1]\n",
    "                    proj2 = proj[N_angles_per_half_circle-1:]\n",
    "\n",
    "        if use_outlier_correction:\n",
    "            print2('\\tRemoving outliers (zingers) for flats ',end='')\n",
    "            flat = fast_pytorch_remove_zingers_chunk(flat, outlier_kernel_half_width, outlier_zinger_threshold, chunk_size = gpu_median_filter_chunk_size).astype('float32')\n",
    "            print2(' Done')\n",
    "\n",
    "            print2('\\tRemoving outliers (zingers) for proj ',end='')\n",
    "            if N_half_circles == 1:\n",
    "                proj = fast_pytorch_remove_zingers_chunk(proj, outlier_kernel_half_width, outlier_zinger_threshold, chunk_size = gpu_median_filter_chunk_size).astype('float32')\n",
    "            elif N_half_circles == 2:\n",
    "                proj1 = fast_pytorch_remove_zingers_chunk(proj1, outlier_kernel_half_width, outlier_zinger_threshold, chunk_size = gpu_median_filter_chunk_size).astype('float32')\n",
    "                proj2 = fast_pytorch_remove_zingers_chunk(proj2, outlier_kernel_half_width, outlier_zinger_threshold, chunk_size = gpu_median_filter_chunk_size).astype('float32')\n",
    "            print2(' Done')\n",
    "\n",
    "        print2('\\tComputing transmission -- ',end='')\n",
    "        flat += -dark_avg\n",
    "        flat_avg = np.mean(flat,axis = 0).astype('float32')\n",
    "        File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+'_bin'+bin_str+'_flat_avg', clear = True).saveTiff(flat_avg)    \n",
    "        if N_half_circles == 1:\n",
    "            proj += -dark_avg\n",
    "            proj /= flat_avg\n",
    "        elif N_half_circles == 2:\n",
    "            proj1 += -dark_avg\n",
    "            proj2 += -dark_avg\n",
    "            N_flat = flat.shape[0]\n",
    "            proj1 /= flat_avg\n",
    "            proj2 /= flat_avg\n",
    "        print2('Done')\n",
    "\n",
    "        if boolean_use_DN:\n",
    "            print2('\\tComputing double normalization -- ',end='')\n",
    "            if N_half_circles == 1:\n",
    "                if boolean_use_DN_row_by_row: \n",
    "                    double_norm = np.reshape(np.mean(proj[:,:,ind_range_DN], axis=2), [proj.shape[0], proj.shape[1],1]) # One coeff per angle & slice (y-axis)\n",
    "                else:\n",
    "                    double_norm = np.reshape(np.mean(proj[:,:,ind_range_DN], axis=(1,2)), [proj.shape[0], 1,1]) # One coeff per angle\n",
    "                proj /= double_norm\n",
    "\n",
    "                if boolean_use_TN:\n",
    "                    triple_norm = np.reshape(np.mean(proj[:,:,ind_range_DN], axis=(0,2)), [1, proj.shape[1],1]) # One coeff per slice (y-axis)\n",
    "                    triple_normB = np.copy(triple_norm)\n",
    "                    triple_normB[triple_normB<0.985] = 0.985\n",
    "                    triple_normB[triple_normB>1.015] = 1.015\n",
    "                    proj /= triple_normB\n",
    "\n",
    "            elif N_half_circles == 2:\n",
    "                if boolean_use_DN_row_by_row: \n",
    "                    double_norm1 = np.reshape(np.mean(proj1[:,:,ind_range_DN], axis=2), [proj1.shape[0], proj1.shape[1],1])\n",
    "                    double_norm2 = np.reshape(np.mean(proj2[:,:,ind_range_DN], axis=2), [proj2.shape[0], proj2.shape[1],1])\n",
    "                else:\n",
    "                    double_norm1 = np.reshape(np.mean(proj1[:,:,ind_range_DN], axis=(1,2)), [proj1.shape[0], 1,1])\n",
    "                    double_norm2 = np.reshape(np.mean(proj2[:,:,ind_range_DN], axis=(1,2)), [proj2.shape[0], 1,1])\n",
    "\n",
    "                proj1 /= double_norm1\n",
    "                proj2 /= double_norm2\n",
    "\n",
    "                if boolean_use_TN:\n",
    "                    triple_norm1 = np.reshape(np.mean(proj1[:,:,ind_range_DN], axis=(0,2)), [1, proj1.shape[1],1])\n",
    "                    triple_norm2 = np.reshape(np.mean(proj2[:,:,ind_range_DN], axis=(0,2)), [1, proj2.shape[1],1])\n",
    "\n",
    "                    triple_norm1B = np.copy(triple_norm1)\n",
    "                    triple_norm1B[triple_norm1B<0.985] = 0.985\n",
    "                    triple_norm1B[triple_norm1B>1.015] = 1.015\n",
    "\n",
    "                    triple_norm2B = np.copy(triple_norm2)\n",
    "                    triple_norm2B[triple_norm2B<0.985] = 0.985\n",
    "                    triple_norm2B[triple_norm2B>1.015] = 1.015\n",
    "\n",
    "                    proj1 /= triple_norm1B\n",
    "                    proj2 /= triple_norm2B\n",
    "            print2('Done')\n",
    "        else:\n",
    "            print2('\\tSkipping double normalization')\n",
    "\n",
    "        print2('\\tWriting PMDOF_DN to tif -- ',end='')\n",
    "        if N_half_circles == 1:\n",
    "            suffix = '_bin'+bin_str+'_PMDOF_DN/'\n",
    "            File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiffStack(proj[ind_save_PMDOF_DN,:,:],ind=ind_save_PMDOF_DN)\n",
    "\n",
    "            if boolean_use_COR:\n",
    "                suffix = suffix[:-1]+'_flippedFirstAngle_COR_'+str(COR).zfill(2)+'/'\n",
    "                proj0 = np.fliplr(apply_offset(proj[0],2*COR))\n",
    "                File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiff(proj0,ind=0)\n",
    "        elif N_half_circles == 2:\n",
    "            suffix = '_bin'+bin_str+'_PMDOF_DN_a_0-180/'\n",
    "            File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiffStack(proj1[ind_save_PMDOF_DN,:,:],ind=ind_save_PMDOF_DN)\n",
    "\n",
    "            if boolean_use_COR:\n",
    "                suffix = suffix[:-1]+'_flippedFirstAngle_COR_'+str(COR).zfill(2)+'/'\n",
    "                proj0 = np.fliplr(apply_offset(proj1[0],2*COR))\n",
    "                File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiff(proj0,ind=0)\n",
    "\n",
    "            if boolean_0_180_range:\n",
    "                suffix = '_bin'+bin_str+'_PMDOF_DN_b_180-0/'\n",
    "            else: \n",
    "                suffix = '_bin'+bin_str+'_PMDOF_DN_b_180-360/'\n",
    "            File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiffStack(proj2[ind_save_PMDOF_DN,:,:],ind=ind_save_PMDOF_DN)\n",
    "\n",
    "            suffix = suffix[:-1]+'_flipped/'\n",
    "            proj2_flipped = np.flip(proj2,axis=0)\n",
    "            File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiffStack(proj2_flipped[ind_save_PMDOF_DN,:,:],ind=ind_save_PMDOF_DN)\n",
    "\n",
    "            if boolean_use_COR:\n",
    "                suffix = suffix[:-1]+'_flippedFirstAngle_COR_'+str(COR).zfill(2)+'/'\n",
    "                proj0 = np.fliplr(apply_offset(proj2[0],2*COR))\n",
    "                File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiff(proj0,ind=0)\n",
    "\n",
    "        print2('Done')\n",
    "\n",
    "        print2('\\tMaking sinograms -- ',end='')\n",
    "        if N_half_circles == 1:\n",
    "            sino = -np.log(np.transpose(proj[:,ind_save_sinogram,:], [1, 0, 2]))\n",
    "        elif N_half_circles == 2:\n",
    "            sino1 = -np.log(np.transpose(proj1[:,ind_save_sinogram,:], [1, 0, 2]))\n",
    "            sino2 = -np.log(np.transpose(proj2[:,ind_save_sinogram,:], [1, 0, 2]))\n",
    "            sino = np.concatenate((sino1,sino2),axis = 1)\n",
    "        print2('Done')\n",
    "\n",
    "        del proj, proj1, proj2\n",
    "        gc.collect()\n",
    "\n",
    "        if save_sinogram:\n",
    "            print2('\\tWriting sinograms to tif -- ',end='')\n",
    "            if N_half_circles == 1:\n",
    "                suffix = '_bin'+bin_str+'_sino/'\n",
    "                File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiffStack(sino,ind=ind_save_sinogram)\n",
    "            elif N_half_circles == 2:\n",
    "                suffix = '_bin'+bin_str+'_sino_a_0-180/'\n",
    "                File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiffStack(sino1,ind=ind_save_sinogram)\n",
    "\n",
    "                if boolean_0_180_range:\n",
    "                    suffix = '_bin'+bin_str+'_sino_b_180-0_flipped/'\n",
    "                else: \n",
    "                    suffix = '_bin'+bin_str+'_sino_b_180-360_flipped/'\n",
    "                File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiffStack(sino2,ind=ind_save_sinogram)\n",
    "            print2('Done')\n",
    "\n",
    "    if boolean_use_COR:\n",
    "        if N_half_circles == 1:\n",
    "            print2('\\tDoing FBP reconstruction -- ',end='')\n",
    "            rec = []\n",
    "            angles = np.linspace(0, np.pi, sino.shape[1], False)\n",
    "            for this_sino in sino:\n",
    "                rec.append(wrapper_ASTRA.FBP(this_sino/pixel_size_cm, filter_type=filter_type, angles = angles, center_rot = COR))\n",
    "            rec = np.array(rec)\n",
    "            print2('Done')\n",
    "            \n",
    "            print2('\\tSaving FBP reconstruction ('+str(rec.shape[0])+' slices) -- ',end='')\n",
    "            suffix = '_bin'+bin_str+'_FBP_COR_'+str(COR).zfill(2)+'/'\n",
    "            File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiffStack(rec,ind=ind_save_sinogram)\n",
    "            print2('Done')\n",
    "            \n",
    "        elif N_half_circles == 2:\n",
    "            print2('\\tDoing FBP reconstruction (1/2) -- ',end='')\n",
    "            rec1 = []\n",
    "#             angles = np.linspace(0, np.pi, sino1.shape[1], False)\n",
    "            angles = angles_to_use1\n",
    "            for this_sino in sino1[::skip_every_slice]:\n",
    "                rec1.append(wrapper_ASTRA.FBP(this_sino/pixel_size_cm, filter_type=filter_type, angles = angles, center_rot = COR))\n",
    "            rec1 = np.array(rec1)\n",
    "            print2('Done (1/2)')\n",
    "            \n",
    "            print2('\\tSaving FBP reconstruction (1/2) -- ',end='')\n",
    "            suffix = '_bin'+bin_str+'_FBP_COR_'+str(COR).zfill(2)+'/'\n",
    "            File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiffStack(rec1,ind=ind_save_sinogram)\n",
    "            print2('Done (1/2)')\n",
    "            \n",
    "            print2('\\tDoing FBP reconstruction (2/2) -- ',end='')\n",
    "            rec2 = []\n",
    "#             angles = np.linspace(0, np.pi, sino2.shape[1], False)\n",
    "            angles = angles_to_use2\n",
    "            for this_sino in sino2[::skip_every_slice]:\n",
    "                rec2.append(wrapper_ASTRA.FBP(this_sino/pixel_size_cm, filter_type=filter_type, angles = angles, center_rot = COR))\n",
    "#                 rec2.append(np.flipud(np.fliplr(wrapper_ASTRA.FBP(this_sino/pixel_size_cm, filter_type=filter_type, angles = angles, center_rot = COR))))\n",
    "            rec2 = np.array(rec2)\n",
    "            print2('Done (2/2)')\n",
    "            \n",
    "            print2('\\tSaving FBP reconstruction (2/2) -- ',end='')\n",
    "            if boolean_0_180_range:\n",
    "                suffix = '_bin'+bin_str+'_FBP_COR_'+str(COR).zfill(2)+'_b_180-0_flipped/'\n",
    "            else:\n",
    "                suffix = '_bin'+bin_str+'_FBP_COR_'+str(COR).zfill(2)+'_b_180-360_flipped/'\n",
    "            File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiffStack(rec2,ind=ind_save_sinogram)\n",
    "            print2('Done (2/2)')\n",
    "            \n",
    "            print2('\\tSaving averaged of two half circles -- ',end='')\n",
    "            suffix = '_bin'+bin_str+'_FBP_COR_'+str(COR).zfill(2)+'_c_averaged_half_circles/'\n",
    "            File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiffStack(0.5*(rec1+rec2),ind=ind_save_sinogram)\n",
    "            print2('Done')\n",
    "            \n",
    "    print2('This took '+str(time.time()-tic)+' s')\n",
    "#     del proj, rec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8696b89",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Pop-up\n",
    "test = read_h5_file(path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871490fc",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Tune COR\n",
    "\n",
    "ind_sino = 150\n",
    "# COR_table = np.linspace(2, 6, 11)\n",
    "COR_table = [2.43/2.0]\n",
    "# COR_table = np.linspace(-1, 1, 11)\n",
    "vmin = 0\n",
    "vmax = 1.5\n",
    "\n",
    "h5py_file = h5py_files[0]\n",
    "\n",
    "if N_half_circles == 1:\n",
    "    bin_dirty = 2\n",
    "    sino3 = sino[:,::bin_dirty,bin_dirty::]\n",
    "else:\n",
    "    # angles = angles_to_use\n",
    "    # angles = np.linspace(0, np.pi, sino3.shape[1], False)\n",
    "    # sino3 = sino\n",
    "    sino3 = sino1\n",
    "    angles = np.linspace(0, np.pi, sino3.shape[1], False)\n",
    "\n",
    "rec = []\n",
    "\n",
    "for COR in COR_table:\n",
    "    rec.append(wrapper_ASTRA.FBP(sino3[ind_sino]/pixel_size_cm, filter_type=filter_type, angles = angles, center_rot = COR))\n",
    "rec = np.array(rec)\n",
    "\n",
    "# pt.plot_3d_stack_slider(rec, vmin = vmin, vmax = vmax)\n",
    "# Nr = rec.shape[1]\n",
    "# window_zoom = 200\n",
    "# # pt.plot_3d_stack_slider(rec[:,Nr//2-window_zoom:Nr//2+window_zoom,Nr//2-window_zoom:Nr//2+window_zoom], vmin = vmin, vmax = vmax)\n",
    "# pt.plot_3d_stack_slider(rec[:,250:750,1500:2000], vmin = vmin, vmax = vmax)\n",
    "\n",
    "suffix = '_tuningCOR'\n",
    "File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+suffix, clear = True).saveTiffStack(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795904eb",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Tune within ~0.1 pixels (then optimal is local anyway)\n",
    "best_ind = 4\n",
    "\n",
    "print('Slice #'+str(best_ind-1)+' - COR is '+str(COR_table[best_ind-1]))\n",
    "print('Slice #'+str(best_ind)+' - COR is '+str(COR_table[best_ind]))\n",
    "print('Slice #'+str(best_ind+1)+' - COR is '+str(COR_table[best_ind+1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5920749b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDoing FBP reconstruction (1/2) -- Done (1/2)\n",
      "\tSaving FBP reconstruction (1/2) -- Done (1/2)\n",
      "\tDoing FBP reconstruction (2/2) -- Done (2/2)\n",
      "\tSaving FBP reconstruction (2/2) -- Done (2/2)\n",
      "\tSaving averaged of two half circles -- Done\n",
      "This took 182.90962982177734 s\n"
     ]
    }
   ],
   "source": [
    "boolean_use_COR = 1\n",
    "COR = 2.43 * 2 / bin_factor # [Pixel]\n",
    "skip_every_slice = 1\n",
    "\n",
    "tic = time.time()\n",
    "if boolean_use_COR:\n",
    "    if N_half_circles == 1:\n",
    "        print2('\\tDoing FBP reconstruction -- ',end='')\n",
    "        rec = []\n",
    "        angles = np.linspace(0, np.pi, sino.shape[1], False)\n",
    "        for this_sino in sino:\n",
    "            rec.append(wrapper_ASTRA.FBP(this_sino/pixel_size_cm, filter_type=filter_type, angles = angles, center_rot = COR))\n",
    "        rec = np.array(rec)\n",
    "        print2('Done')\n",
    "\n",
    "        print2('\\tSaving FBP reconstruction ('+str(rec.shape[0])+' slices) -- ',end='')\n",
    "        suffix = '_bin'+bin_str+'_FBP_COR_'+str(COR).zfill(2)+'/'\n",
    "        File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiffStack(rec,ind=ind_save_sinogram)\n",
    "        print2('Done')\n",
    "\n",
    "    elif N_half_circles == 2:\n",
    "        print2('\\tDoing FBP reconstruction (1/2) -- ',end='')\n",
    "        rec1 = []\n",
    "#             angles = np.linspace(0, np.pi, sino1.shape[1], False)\n",
    "        angles = angles_to_use1\n",
    "        for this_sino in sino1[::skip_every_slice]:\n",
    "            rec1.append(wrapper_ASTRA.FBP(this_sino/pixel_size_cm, filter_type=filter_type, angles = angles, center_rot = COR))\n",
    "        rec1 = np.array(rec1)\n",
    "        print2('Done (1/2)')\n",
    "\n",
    "        print2('\\tSaving FBP reconstruction (1/2) -- ',end='')\n",
    "        suffix = '_bin'+bin_str+'_FBP_COR_'+str(COR).zfill(2)+'/'\n",
    "        File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiffStack(rec1,ind=ind_save_sinogram)\n",
    "        print2('Done (1/2)')\n",
    "\n",
    "        print2('\\tDoing FBP reconstruction (2/2) -- ',end='')\n",
    "        rec2 = []\n",
    "#             angles = np.linspace(0, np.pi, sino2.shape[1], False)\n",
    "        angles = angles_to_use2\n",
    "        for this_sino in sino2[::skip_every_slice]:\n",
    "            rec2.append(wrapper_ASTRA.FBP(this_sino/pixel_size_cm, filter_type=filter_type, angles = angles, center_rot = COR))\n",
    "#                 rec2.append(np.flipud(np.fliplr(wrapper_ASTRA.FBP(this_sino/pixel_size_cm, filter_type=filter_type, angles = angles, center_rot = COR))))\n",
    "        rec2 = np.array(rec2)\n",
    "        print2('Done (2/2)')\n",
    "\n",
    "        print2('\\tSaving FBP reconstruction (2/2) -- ',end='')\n",
    "        if boolean_0_180_range:\n",
    "            suffix = '_bin'+bin_str+'_FBP_COR_'+str(COR).zfill(2)+'_b_180-0_flipped/'\n",
    "        else:\n",
    "            suffix = '_bin'+bin_str+'_FBP_COR_'+str(COR).zfill(2)+'_b_180-360_flipped/'\n",
    "        File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiffStack(rec2,ind=ind_save_sinogram)\n",
    "        print2('Done (2/2)')\n",
    "\n",
    "        print2('\\tSaving averaged of two half circles -- ',end='')\n",
    "        suffix = '_bin'+bin_str+'_FBP_COR_'+str(COR).zfill(2)+'_c_averaged_half_circles/'\n",
    "        File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiffStack(0.5*(rec1+rec2),ind=ind_save_sinogram)\n",
    "        print2('Done')\n",
    "\n",
    "print2('This took '+str(time.time()-tic)+' s')\n",
    "#     del proj, rec\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "658965b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (1/2)\n",
      "Done (2/2)\n",
      "Done (2/2)\n"
     ]
    }
   ],
   "source": [
    "# Test FBP 0-180 vs 180-360 vs Mean of both vs 0-360\n",
    "\n",
    "angles = angles_to_use1\n",
    "this_sino = sino1[sino1.shape[0]//2]\n",
    "rec1 = wrapper_ASTRA.FBP(this_sino/pixel_size_cm, filter_type=filter_type, angles = angles, center_rot = COR)\n",
    "print2('Done (1/2)')\n",
    "tifffile.imsave(path_save+'rec1.tif', rec1.astype('float32'))\n",
    "\n",
    "# print2('\\tSaving FBP reconstruction (1/2) -- ',end='')\n",
    "# suffix = '_bin'+bin_str+'_FBP_COR_'+str(COR).zfill(2)+'/'\n",
    "# File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiffStack(rec1,ind=ind_save_sinogram)\n",
    "# print2('Done (1/2)')\n",
    "\n",
    "angles = angles_to_use2\n",
    "this_sino = sino2[sino2.shape[0]//2]\n",
    "rec2 = wrapper_ASTRA.FBP(this_sino/pixel_size_cm, filter_type=filter_type, angles = angles, center_rot = COR)\n",
    "print2('Done (2/2)')\n",
    "tifffile.imsave(path_save+'rec2.tif', rec2.astype('float32'))\n",
    "\n",
    "tifffile.imsave(path_save+'rec12_mean.tif', 0.5*(rec1+rec2).astype('float32'))\n",
    "\n",
    "sino = np.concatenate((sino1,sino2),axis = 1)\n",
    "angles = angles_to_use\n",
    "this_sino = sino[sino.shape[0]//2]\n",
    "rec2 = wrapper_ASTRA.FBP(this_sino/pixel_size_cm, filter_type=filter_type, angles = angles, center_rot = COR)\n",
    "print2('Done (2/2)')\n",
    "tifffile.imsave(path_save+'rec12_atOnce.tif', rec2.astype('float32'))\n",
    "# print2('\\tSaving FBP reconstruction (2/2) -- ',end='')\n",
    "# if boolean_0_180_range:\n",
    "#     suffix = '_bin'+bin_str+'_FBP_COR_'+str(COR).zfill(2)+'_b_180-0_flipped/'\n",
    "# else: \n",
    "#     suffix = '_bin'+bin_str+'_FBP_COR_'+str(COR).zfill(2)+'_b_180-360_flipped/'\n",
    "# File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiffStack(rec2,ind=ind_save_sinogram)\n",
    "# print2('Done (2/2)')\n",
    "\n",
    "# print2('\\tSaving averaged of two half circles -- ',end='')\n",
    "# suffix = '_bin'+bin_str+'_FBP_COR_'+str(COR).zfill(2)+'_c_averaged_half_circles/'\n",
    "# File.File(h5py_file.path_folder+h5py_file.file_name_noExtension+'/'+h5py_file.file_name_noExtension+added_suffix+suffix, clear = True).saveTiffStack(0.5*(rec1+rec2),ind=ind_save_sinogram)\n",
    "# print2('Done')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
