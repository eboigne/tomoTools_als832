{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>.container { width:90% !important; }</style>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/u2/e/eboigne/tomoTools_als832/tomoTools\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import ipywidgets\n",
    "ipywidgets.Widget.close_all()\n",
    "\n",
    "import SimpleITK\n",
    "import datetime\n",
    "import gc # Garbage collected\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import time\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename, askopenfilenames, askdirectory\n",
    "import torch\n",
    "import skimage\n",
    "from skimage import measure\n",
    "from skimage.morphology import skeletonize\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import sknw # https://github.com/Image-Py/sknw\n",
    "\n",
    "this_path = os.getcwd()\n",
    "print(this_path)\n",
    "\n",
    "\n",
    "import h5py\n",
    "# import File\n",
    "from scripts import *\n",
    "import wrapper_ASTRA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', '02', '03', '04', '05', '06', '07', '08a', '08b', '09a', '09b', '10a', '10b', '11a', '11b', '12a', '12b', '13a', '13b', '14a', '14b', '15a', '15b', '16a', '16b', '17a', '17b', '18a', '18b', '19a', '19b', '20a', '20b', '21a', '21b', '22', '23', '24']\n"
     ]
    }
   ],
   "source": [
    "path_save = '/global/homes/e/eboigne/cfs_als/2022_wood/'\n",
    "\n",
    "# case = 'run21_oak_lowHeat'\n",
    "# case = 'run23_walnut_lowHeat'\n",
    "case = 'run24_birch_lowHeat'\n",
    "# case = 'run26_birch_highHeat'\n",
    "\n",
    "voxel_size = 3.24*2 # [microns]\n",
    "\n",
    "list_cases_folder_name = sorted([e for e in os.listdir(path_save+case) if not 'probe' in e and not '.tif' in e and not '.pickle' in e])\n",
    "run = case[3:5]+'_Sample'\n",
    "list_cases_h5 = sorted([e for e in os.listdir(path_save) if '.h5' in e and run in e])\n",
    "\n",
    "print(list_cases_folder_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% WHich case to look at?\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 01\n",
      "1 02\n",
      "2 03\n",
      "3 04\n",
      "4 05\n",
      "5 06\n",
      "6 07\n",
      "7 08a\n",
      "8 08b\n",
      "9 09a\n",
      "10 09b\n",
      "11 10a\n",
      "12 10b\n",
      "13 11a\n",
      "14 11b\n",
      "15 12a\n",
      "16 12b\n",
      "17 13a\n",
      "18 13b\n",
      "19 14a\n",
      "20 14b\n",
      "21 15a\n",
      "22 15b\n",
      "23 16a\n",
      "24 16b\n",
      "25 17a\n",
      "26 17b\n",
      "27 18a\n",
      "28 18b\n",
      "29 19a\n",
      "30 19b\n",
      "31 20a\n",
      "32 20b\n",
      "33 21a\n",
      "34 21b\n",
      "35 22\n",
      "36 23\n",
      "37 24\n",
      "(38, 1280, 1280)\n"
     ]
    }
   ],
   "source": [
    "ind_slice = 250\n",
    "\n",
    "slices = []\n",
    "for ind_case, this_case in enumerate(list_cases_folder_name[:]):\n",
    "    slices.append(File(path_save+case+'/'+this_case+'/b_movingRegisteredToStatic/').read(ind_slice))\n",
    "    print(ind_case, this_case)\n",
    "\n",
    "slices = np.array(slices)\n",
    "print(slices.shape)\n",
    "File(path_save+case+'/probe_slice_'+str(ind_slice).zfill(4)).saveTiffStack(slices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Probe one slice\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (0, '01') c 62666.0\n",
      "2 (1, '02') c 62972.0\n",
      "3 (2, '03') c 63291.0\n",
      "4 (3, '04') c 63812.0\n",
      "5 (4, '05') c 64069.0\n",
      "6 (5, '06') c 64249.0\n",
      "7 (6, '07') c 64434.0\n",
      "9 (7, '08') a/b 64616.0 64642.26\n",
      "11 (8, '09') a/b 64813.0 64839.26\n",
      "13 (9, '10') a/b 65005.0 65031.26\n",
      "15 (10, '11') a/b 65187.0 65213.26\n",
      "17 (11, '12') a/b 65369.0 65395.26\n",
      "19 (12, '13') a/b 65553.0 65579.26\n",
      "21 (13, '14') a/b 65736.0 65762.26\n",
      "23 (14, '15') a/b 65932.0 65958.26\n",
      "25 (15, '16') a/b 66121.0 66147.26\n",
      "27 (16, '17') a/b 66304.0 66330.26\n",
      "29 (17, '18') a/b 66488.0 66514.26\n",
      "31 (18, '19') a/b 66673.0 66699.26\n",
      "33 (19, '20') a/b 66864.0 66890.26\n",
      "35 (20, '21') a/b 67049.0 67075.26\n",
      "36 (21, '22') c 67247.0\n",
      "37 (22, '23') c 67552.0\n",
      "38 (23, '24') c 67860.0\n"
     ]
    }
   ],
   "source": [
    "c = []\n",
    "for this_case in enumerate(list_cases_h5):\n",
    "    c.append(this_case[1][35:37])\n",
    "\n",
    "t = []\n",
    "\n",
    "list_scans = []\n",
    "\n",
    "for this_case in enumerate(c):\n",
    "    if str(this_case[1]) in list_cases_folder_name:\n",
    "        cc = list_cases_h5[this_case[0]][9:15]\n",
    "        h = cc[0:2]\n",
    "        m = cc[2:4]\n",
    "        s = cc[4:]\n",
    "        ts = float(int(h)*3600+int(m)*60+int(s))\n",
    "        t.append(ts) #c\n",
    "        print(len(t), this_case, 'c', ts)\n",
    "    else:\n",
    "        cc = list_cases_h5[this_case[0]][9:15]\n",
    "        h = cc[0:2]\n",
    "        m = cc[2:4]\n",
    "        s = cc[4:]\n",
    "        ts0 = float(int(h)*3600+int(m)*60+int(s))\n",
    "        t.append(ts0) #a\n",
    "        ts1 = 26.26 + ts0\n",
    "        t.append(ts1) #b\n",
    "        print(len(t), this_case, 'a/b', ts0 ,ts1)\n",
    "\n",
    "scan_times = np.array(t) - t[0]\n",
    "\n",
    "assert(len(list_cases_folder_name) ==len(scan_times)), 'Wrong sizes'\n",
    "\n",
    "for ind_scan,scan_time in enumerate(scan_times):\n",
    "    this_scan = Data()\n",
    "    this_scan.scan_time = scan_time\n",
    "    this_scan.folder_name = list_cases_folder_name[ind_scan]\n",
    "    this_scan.full_path = path_save+case+'/'+this_scan.folder_name\n",
    "    this_scan.ind = ind_scan\n",
    "    list_scans.append(this_scan)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Setup times and scan list\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def compute_mask_solid(this_scan, force_redo = False):\n",
    "\n",
    "    if force_redo or not 'b_movingRegisteredToStatic_maskSolid' in os.listdir(this_scan.full_path):\n",
    "\n",
    "        # Loading data\n",
    "        tic = time.time()\n",
    "        data = File(path_save+case+'/'+this_scan.folder_name+'/b_movingRegisteredToStatic/').readAll()\n",
    "        print('\\tLoading data took: '+str(time.time()-tic))\n",
    "\n",
    "        threshold = 0.05 # Linear attenuation threshold [/cm], gas to wood\n",
    "        threshold_needle = 4.0 # Linear attenuation threshold [/cm]\n",
    "        mask_growth_needle = 10 # Grow the mask obtained using threshold_needle with this amount of pixels\n",
    "        mask_enclosing_circle = tifffile.imread(path_save+case+'/maskEnclosingCircle.tif') > 0\n",
    "        bin_factor_dilatation = 1 # Binning before smoothing, as an option to speed things up for large kernels\n",
    "        filter_half_width = 3 # After binning (equal to sigma for gaussian filter)\n",
    "\n",
    "        kernel = custom_3d_gaussian_filter(filter_half_width)\n",
    "\n",
    "        if bin_factor_dilatation > 1:\n",
    "            data_smoothed = fast_pytorch_bin_3d(data,bin_factor_dilatation, chunk_size = 71)\n",
    "        else:\n",
    "            data_smoothed = data\n",
    "\n",
    "        data_smoothed = apply_3d_image_processing_on_subvolumes(data_smoothed, fast_pytorch_convolution, kernel_array = kernel, chunk_size_max = (500, 500, 500), overlap = 3*filter_half_width)\n",
    "\n",
    "        if bin_factor_dilatation > 1:\n",
    "            data_smoothed = skimage.transform.rescale(data_smoothed, bin_factor_dilatation, multichannel=False)\n",
    "\n",
    "        mask_needle = data_smoothed > threshold_needle\n",
    "        mask_needle = apply_3d_image_processing_on_subvolumes(mask_needle, fast_pytorch_mask_dilation, chunk_size_max = (500, 500, 500), overlap = mask_growth_needle, radius = mask_growth_needle)\n",
    "\n",
    "        mask_solid = data_smoothed > threshold\n",
    "        mask_solid[mask_needle] = False\n",
    "\n",
    "        for ind, slice in enumerate(mask_solid):\n",
    "            slice[~mask_enclosing_circle] = False\n",
    "            mask_solid[ind] = slice\n",
    "\n",
    "        File(this_scan.full_path+'/b_movingRegisteredToStatic_maskSolid').saveTiffStack(mask_solid, type = 'bool')\n",
    "    else:\n",
    "        print('\\tRe-loading mask solid')\n",
    "        mask_solid = File(this_scan.full_path+'/b_movingRegisteredToStatic_maskSolid').readAll()\n",
    "\n",
    "    return(mask_solid.astype('bool'))\n",
    "\n",
    "def close_mask_solid(this_scan, mask_solid, force_redo = False):\n",
    "\n",
    "    if force_redo or not 'b_movingRegisteredToStatic_maskSolidClosed' in os.listdir(this_scan.full_path):\n",
    "\n",
    "        filter_half_width = 12\n",
    "        chunk_size = (500, 500, 500)\n",
    "\n",
    "        # Morphological closing: closing the pores\n",
    "        structure = custom_3d_kernel_sphere(filter_half_width)\n",
    "        mask_solid_dilated = apply_3d_image_processing_on_subvolumes(mask_solid, fast_pytorch_mask_dilation, chunk_size_max = chunk_size, overlap = filter_half_width, radius = filter_half_width)\n",
    "        mask_solid_closed = ~apply_3d_image_processing_on_subvolumes(~mask_solid_dilated, fast_pytorch_mask_dilation, chunk_size_max = chunk_size, overlap = filter_half_width, radius = filter_half_width)\n",
    "\n",
    "        File(this_scan.full_path+'/b_movingRegisteredToStatic_maskSolidClosed').saveTiffStack(mask_solid_closed, type = 'bool')\n",
    "\n",
    "    else:\n",
    "        print('\\tRe-loading mask solid closed')\n",
    "        mask_solid_closed = File(this_scan.full_path+'/b_movingRegisteredToStatic_maskSolidClosed').readAll()\n",
    "\n",
    "    return(mask_solid_closed.astype('bool'))\n",
    "\n",
    "def compute_height(properties):\n",
    "    for prop in properties:\n",
    "        bbox = prop.bbox\n",
    "        prop.height = bbox[3]-bbox[0] # Along z, in pixels\n",
    "    return(properties)\n",
    "\n",
    "def compute_equivalent_cylinder_diameters(properties):\n",
    "    for prop in properties:\n",
    "        equivalent_cylinder_cross_section = prop.area / prop.height\n",
    "        prop.equivalent_cylinder_diameter = np.sqrt(4*equivalent_cylinder_cross_section/np.pi) * voxel_size\n",
    "    return(properties)\n",
    "\n",
    "def get_path_length(graph, path):\n",
    "    this_sum=0\n",
    "    for i in range(len(path)-1):\n",
    "        this_sum += graph.get_edge_data(path[i], path[i+1])['weight']\n",
    "    return(this_sum)\n",
    "\n",
    "def longest_simple_path(graph, source, target):\n",
    "    longest_path = None\n",
    "    longest_path_length = 0\n",
    "    for path in nx.all_simple_paths(graph, source=source, target=target):\n",
    "        path_length = get_path_length(graph,path)\n",
    "        if path_length > longest_path_length:\n",
    "            longest_path_length = path_length\n",
    "            longest_path = path\n",
    "    return longest_path, longest_path_length\n",
    "\n",
    "def find_longest_subgraph_from_ends(graph, bbox):\n",
    "\n",
    "    ind_end_nodes = [x for x in graph.nodes if graph.degree(x) == 1]\n",
    "    ind_end_bottom = [x for x in ind_end_nodes if graph.nodes[x]['o'][0] - bbox[0] <=  bbox[3] - graph.nodes[x]['o'][0]]\n",
    "    ind_end_top = [x for x in ind_end_nodes if not x in ind_end_bottom]\n",
    "\n",
    "    longest_path_subgraph = None\n",
    "    longest_path_length = 0\n",
    "    longest_path = []\n",
    "    for ind_bot in ind_end_bottom:\n",
    "        for ind_top in ind_end_top:\n",
    "            this_longest_path, this_longest_path_length = longest_simple_path(graph, source=ind_bot, target=ind_top)\n",
    "            this_longest_path_subgraph = graph.subgraph(this_longest_path)\n",
    "\n",
    "            if this_longest_path_length > longest_path_length:\n",
    "                longest_path_length = this_longest_path_length\n",
    "                longest_path = this_longest_path\n",
    "                longest_path_subgraph = this_longest_path_subgraph\n",
    "\n",
    "    return(longest_path_subgraph, longest_path, longest_path_length)\n",
    "\n",
    "def compute_tortuosity(skeleton_properties):\n",
    "\n",
    "    for ind_pore in range(len(skeleton_properties)):\n",
    "        bbox = skeleton_properties[ind_pore].bbox\n",
    "        graph = sknw.build_sknw(skeleton_properties[ind_pore].image, multi=False, iso=False, ring=False, full=True)\n",
    "        longest_path_subgraph, longest_path, longest_path_length = find_longest_subgraph_from_ends(graph, bbox)\n",
    "\n",
    "        if longest_path_length == 0:\n",
    "            longest_path_length = np.nan\n",
    "\n",
    "        skeleton_properties[ind_pore].length_skeleton = longest_path_length\n",
    "        skeleton_properties[ind_pore].longest_path = longest_path\n",
    "        # skeleton_properties[ind_pore].longest_path_subgraph = longest_path_subgraph\n",
    "        skeleton_properties[ind_pore].tortuosity = longest_path_length / skeleton_properties[ind_pore].height\n",
    "\n",
    "        # print(ind_pore, longest_path_length, skeleton_properties[ind_pore].tortuosity)\n",
    "    return(skeleton_properties)\n",
    "\n",
    "def compute_skeleton(this_scan, mask_pores, force_redo = False):\n",
    "\n",
    "    if force_redo or not 'b_movingRegisteredToStatic_maskPores_skeleton' in os.listdir(this_scan.full_path):\n",
    "        skeleton = skeletonize(mask_pores)\n",
    "        File(this_scan.full_path+'/b_movingRegisteredToStatic_maskPores_skeleton').saveTiffStack(skeleton, type = 'bool')\n",
    "    else:\n",
    "        print('\\tRe-loading skeleton')\n",
    "        skeleton = File(this_scan.full_path+'/b_movingRegisteredToStatic_maskPores_skeleton').readAll()\n",
    "    return(skeleton)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Function to compute mask_solid\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07\n"
     ]
    }
   ],
   "source": [
    "with open(path_save+case+'/post_pro_data.pickle', 'rb') as handle:\n",
    "    list_scans = pickle.load(handle)\n",
    "\n",
    "print(list_scans[6].folder_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running scan #0/38 - 07\n",
      "\tLoading data took: 44.93602132797241\n",
      "\t Processing 18 chunks of size [349 426 426] .................. Done\n",
      "\t Processing 18 chunks of size [349 426 426] .................. Done\n",
      "\tClosing mask solid\n",
      "\t Processing 18 chunks of size [349 426 426] .................. Done\n",
      "\t Processing 18 chunks of size [349 426 426] .................. Done\n",
      "\tParticle identification and analysis took: 14.394068717956543\n",
      "\tSkeletonize and analysis took: 97.03547191619873\n",
      "\tUpdating save pickle\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Re-load scan data\n",
    "with open(path_save+case+'/post_pro_data.pickle', 'rb') as handle:\n",
    "    list_scans = pickle.load(handle)\n",
    "\n",
    "nb_scans = len(list_scans)\n",
    "force_redo = False\n",
    "\n",
    "for ind_scan,this_scan in enumerate(list_scans[6:7]):\n",
    "\n",
    "    print('Running scan #'+str(ind_scan)+'/'+str(nb_scans)+' - '+this_scan.folder_name)\n",
    "\n",
    "    # Loading data and computing mask solid\n",
    "    mask_solid = compute_mask_solid(this_scan, force_redo = force_redo)\n",
    "\n",
    "    # Crop mask solid\n",
    "    ind_bottom = 100\n",
    "    ind_top = 610\n",
    "    mask_solid[:ind_bottom] = False\n",
    "    mask_solid[ind_top:] = False\n",
    "\n",
    "    # Close mask_solid and compute porosity\n",
    "    print('\\tClosing mask solid')\n",
    "    mask_solid_closed = close_mask_solid(this_scan, mask_solid, force_redo = force_redo)\n",
    "\n",
    "    # Compute porosity\n",
    "    this_scan.porosity = 1 - np.sum(mask_solid.flatten()) / np.sum(mask_solid_closed.flatten())\n",
    "\n",
    "    # Analyze pore structure\n",
    "    mask_pores = mask_solid_closed * (~mask_solid)\n",
    "    tic = time.time()\n",
    "    lab = measure.label(mask_pores)\n",
    "    properties = np.array(measure.regionprops(lab))\n",
    "    print('\\tParticle identification and analysis took: '+str(time.time()-tic))\n",
    "\n",
    "    # Cleaning up pores\n",
    "    properties = compute_height(properties)\n",
    "    areas = np.array([prop.area for prop in properties])\n",
    "    height = np.array([prop.height for prop in properties])\n",
    "    this_scan.ind_properties_cleaned = np.where((areas>500) * (areas < 300000) * (height > 100))[0]\n",
    "    properties_cleaned = properties[this_scan.ind_properties_cleaned]\n",
    "\n",
    "    # Compute equivalent cylinder diameters\n",
    "    properties_cleaned = compute_equivalent_cylinder_diameters(properties_cleaned)\n",
    "    this_scan.nb_pores = len(properties_cleaned)\n",
    "    # this_scan.pore_properties = properties_cleaned # Don't save this, otherwise pickle too heavy (image data stored)\n",
    "\n",
    "    # Build and analyze skeleton for tortuosity\n",
    "    tic = time.time()\n",
    "    skeleton = compute_skeleton(this_scan, mask_pores, force_redo = force_redo)\n",
    "    skeleton_lab = measure.label(skeleton)\n",
    "    skeleton_properties = measure.regionprops(skeleton_lab)\n",
    "    print('\\tSkeletonize and analysis took: '+str(time.time()-tic))\n",
    "\n",
    "    # Extract which pores to keep from skeleton\n",
    "    skeleton_properties = compute_height(skeleton_properties)\n",
    "    skeleton_areas = np.array([prop.area for prop in skeleton_properties])\n",
    "    skeleton_height = np.array([prop.height for prop in skeleton_properties])\n",
    "    this_scan.skeleton_ind_properties_cleaned = np.where((skeleton_areas>50) * (skeleton_areas < 1000) * (skeleton_height > 100))[0]\n",
    "\n",
    "    # Compute tortuosity for each pore\n",
    "    skeleton_properties_cleaned = compute_tortuosity(np.array(skeleton_properties)[this_scan.skeleton_ind_properties_cleaned])\n",
    "\n",
    "    # Save relevant pore & skeleton properties\n",
    "    this_scan.areas = [prop.area for prop in properties_cleaned]\n",
    "    this_scan.equivalent_cylinder_diameters = [prop.equivalent_cylinder_diameter for prop in properties_cleaned]\n",
    "    this_scan.heights = [prop.height for prop in properties_cleaned]\n",
    "    this_scan.skeleton_pore_path_length = [prop.length_skeleton for prop in skeleton_properties_cleaned]\n",
    "    this_scan.tortuosity = [prop.tortuosity for prop in skeleton_properties_cleaned if not np.isnan(prop.tortuosity)]\n",
    "\n",
    "    # Update save of scan data\n",
    "    print('\\tUpdating save pickle')\n",
    "    with open(path_save+case+'/post_pro_data.pickle', 'wb') as handle:\n",
    "        pickle.dump(list_scans, handle)\n",
    "\n",
    "print('Done')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Main loop: run over all scans\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "with open(path_save+case+'/post_pro_data.pickle', 'rb') as handle:\n",
    "    list_scans = pickle.load(handle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Load scan data\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.15787853881702962\n",
      "677\n"
     ]
    }
   ],
   "source": [
    "ind_scan = 0\n",
    "\n",
    "print(list_scans[ind_scan].ind)\n",
    "print(list_scans[ind_scan].porosity)\n",
    "print(list_scans[ind_scan].nb_pores)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading scan #0/38 - 01\n",
      "\tLoading data took: 42.07638478279114\n",
      "Loading scan #1/38 - 02\n",
      "\tLoading data took: 40.69148349761963\n",
      "Loading scan #2/38 - 03\n",
      "\tLoading data took: 41.73680543899536\n",
      "Loading scan #3/38 - 04\n",
      "\tLoading data took: 62.18978476524353\n",
      "Loading scan #4/38 - 05\n",
      "\tLoading data took: 65.98088431358337\n",
      "Loading scan #5/38 - 06\n",
      "\tLoading data took: 74.47796487808228\n",
      "Loading scan #6/38 - 07\n",
      "\tLoading data took: 62.119035959243774\n",
      "Loading scan #7/38 - 08a\n",
      "\tLoading data took: 65.75326943397522\n",
      "Loading scan #8/38 - 08b\n"
     ]
    }
   ],
   "source": [
    "ind_slice_X = 600-1 # Reslice from Top in Fiji\n",
    "ind_slice_Y = 620-1 # Reslice from Left in Fiji\n",
    "nb_scans = len(list_scans)\n",
    "\n",
    "for ind_scan,this_scan in enumerate(list_scans):\n",
    "\n",
    "    print('Loading scan #'+str(ind_scan)+'/'+str(nb_scans)+' - '+this_scan.folder_name)\n",
    "\n",
    "    # Loading data\n",
    "    tic = time.time()\n",
    "    data = File(path_save+case+'/'+this_scan.folder_name+'/b_movingRegisteredToStatic/').readAll()\n",
    "    print('\\tLoading data took: '+str(time.time()-tic))\n",
    "\n",
    "    File(path_save+case+'/probe_sliceX_'+str(ind_slice_X).zfill(4)).saveTiff(data[:,ind_slice_X,:], ind = this_scan.ind)\n",
    "    File(path_save+case+'/probe_sliceY_'+str(ind_slice_Y).zfill(4)).saveTiff(data[:,:,ind_slice_Y], ind = this_scan.ind)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Export vertical slices\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}