{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/als/users/eboigne/cfoster/code/als6/tomoTools_als832/tomoTools\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import ipywidgets\n",
    "ipywidgets.Widget.close_all()\n",
    "\n",
    "import SimpleITK\n",
    "import datetime\n",
    "import gc # Garbage collected\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import time\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename, askopenfilenames, askdirectory\n",
    "import torch\n",
    "import skimage\n",
    "from skimage import measure\n",
    "from skimage.morphology import skeletonize\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import sknw # https://github.com/Image-Py/sknw\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "this_path = os.getcwd()\n",
    "print(this_path)\n",
    "\n",
    "\n",
    "import h5py\n",
    "# import File\n",
    "from scripts import *\n",
    "import wrapper_ASTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% WHich case to look at?\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01', '02', '03', '04', '05', '06', '07', '08a', '08b', '09a', '09b', '10a', '10b', '11a', '11b', '12a', '12b', '13a', '13b', '14a', '14b', '15a', '15b', '16a', '16b', '17a', '17b', '18a', '18b', '19a', '19b', '20a', '20b', '21a', '21b', '22', '23', '24']\n"
     ]
    }
   ],
   "source": [
    "path_save = '/global/homes/e/eboigne/cfs_als/2022_wood/'\n",
    "\n",
    "# case = 'run21_oak_lowHeat'\n",
    "# case = 'run23_walnut_lowHeat'\n",
    "case = 'run24_birch_lowHeat'\n",
    "# case = 'run26_birch_highHeat'\n",
    "\n",
    "voxel_size = 3.24*2 # [microns]\n",
    "\n",
    "list_cases_folder_name = sorted([e for e in os.listdir(path_save+case) if not 'probe' in e and not '.tif' in e and not '.pickle' in e])\n",
    "run = case[3:5]+'_Sample'\n",
    "list_cases_h5 = sorted([e for e in os.listdir(path_save) if '.h5' in e and run in e])\n",
    "\n",
    "print(list_cases_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Probe one slice\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 01\n",
      "1 02\n",
      "2 03\n",
      "3 04\n",
      "4 05\n",
      "5 06\n",
      "6 07\n",
      "7 08a\n",
      "8 08b\n",
      "9 09a\n",
      "10 09b\n",
      "11 10a\n",
      "12 10b\n",
      "13 11a\n",
      "14 11b\n",
      "15 12a\n",
      "16 12b\n",
      "17 13a\n",
      "18 13b\n",
      "19 14a\n",
      "20 14b\n",
      "21 15a\n",
      "22 15b\n",
      "23 16a\n",
      "24 16b\n",
      "25 17a\n",
      "26 17b\n",
      "27 18a\n",
      "28 18b\n",
      "29 19a\n",
      "30 19b\n",
      "31 20a\n",
      "32 20b\n",
      "33 21a\n",
      "34 21b\n",
      "35 22\n",
      "36 23\n",
      "37 24\n",
      "(38, 1280, 1280)\n"
     ]
    }
   ],
   "source": [
    "ind_slice = 250\n",
    "\n",
    "slices = []\n",
    "for ind_case, this_case in enumerate(list_cases_folder_name[:]):\n",
    "    slices.append(File(path_save+case+'/'+this_case+'/b_movingRegisteredToStatic/').read(ind_slice))\n",
    "    print(ind_case, this_case)\n",
    "\n",
    "slices = np.array(slices)\n",
    "print(slices.shape)\n",
    "File(path_save+case+'/probe_slice_'+str(ind_slice).zfill(4)).saveTiffStack(slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Setup times and scan list\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (0, '01') c 62666.0\n",
      "2 (1, '02') c 62972.0\n",
      "3 (2, '03') c 63291.0\n",
      "4 (3, '04') c 63812.0\n",
      "5 (4, '05') c 64069.0\n",
      "6 (5, '06') c 64249.0\n",
      "7 (6, '07') c 64434.0\n",
      "9 (7, '08') a/b 64616.0 64642.26\n",
      "11 (8, '09') a/b 64813.0 64839.26\n",
      "13 (9, '10') a/b 65005.0 65031.26\n",
      "15 (10, '11') a/b 65187.0 65213.26\n",
      "17 (11, '12') a/b 65369.0 65395.26\n",
      "19 (12, '13') a/b 65553.0 65579.26\n",
      "21 (13, '14') a/b 65736.0 65762.26\n",
      "23 (14, '15') a/b 65932.0 65958.26\n",
      "25 (15, '16') a/b 66121.0 66147.26\n",
      "27 (16, '17') a/b 66304.0 66330.26\n",
      "29 (17, '18') a/b 66488.0 66514.26\n",
      "31 (18, '19') a/b 66673.0 66699.26\n",
      "33 (19, '20') a/b 66864.0 66890.26\n",
      "35 (20, '21') a/b 67049.0 67075.26\n",
      "36 (21, '22') c 67247.0\n",
      "37 (22, '23') c 67552.0\n",
      "38 (23, '24') c 67860.0\n"
     ]
    }
   ],
   "source": [
    "c = []\n",
    "for this_case in enumerate(list_cases_h5):\n",
    "    c.append(this_case[1][35:37])\n",
    "\n",
    "t = []\n",
    "\n",
    "list_scans = []\n",
    "\n",
    "for this_case in enumerate(c):\n",
    "    if str(this_case[1]) in list_cases_folder_name:\n",
    "        cc = list_cases_h5[this_case[0]][9:15]\n",
    "        h = cc[0:2]\n",
    "        m = cc[2:4]\n",
    "        s = cc[4:]\n",
    "        ts = float(int(h)*3600+int(m)*60+int(s))\n",
    "        t.append(ts) #c\n",
    "        print(len(t), this_case, 'c', ts)\n",
    "    else:\n",
    "        cc = list_cases_h5[this_case[0]][9:15]\n",
    "        h = cc[0:2]\n",
    "        m = cc[2:4]\n",
    "        s = cc[4:]\n",
    "        ts0 = float(int(h)*3600+int(m)*60+int(s))\n",
    "        t.append(ts0) #a\n",
    "        ts1 = 26.26 + ts0\n",
    "        t.append(ts1) #b\n",
    "        print(len(t), this_case, 'a/b', ts0 ,ts1)\n",
    "\n",
    "scan_times = np.array(t) - t[0]\n",
    "\n",
    "\n",
    "for ind_scan,scan_time in enumerate(scan_times[:-1]):\n",
    "    this_scan = Data()\n",
    "    this_scan.scan_time = scan_time\n",
    "    this_scan.folder_name = list_cases_folder_name[ind_scan]\n",
    "    this_scan.full_path = path_save+case+'/'+this_scan.folder_name\n",
    "    this_scan.ind = ind_scan\n",
    "    list_scans.append(this_scan)\n",
    "\n",
    "assert(len(list_cases_folder_name) ==len(scan_times)), 'Wrong sizes'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "print(len(list_scans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Function to compute mask_solid\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_mask_solid(this_scan, data, force_redo = False):\n",
    "\n",
    "    if force_redo or not 'b_movingRegisteredToStatic_maskSolid' in os.listdir(this_scan.full_path):\n",
    "\n",
    "        threshold = 0.05 # Linear attenuation threshold [/cm], gas to wood\n",
    "        threshold_needle = 4.0 # Linear attenuation threshold [/cm]\n",
    "        mask_growth_needle = 10 # Grow the mask obtained using threshold_needle with this amount of pixels\n",
    "        mask_enclosing_circle = tifffile.imread(path_save+case+'/maskEnclosingCircle.tif') > 0\n",
    "        bin_factor_dilatation = 1 # Binning before smoothing, as an option to speed things up for large kernels\n",
    "        filter_half_width = 3 # After binning (equal to sigma for gaussian filter)\n",
    "\n",
    "        kernel = custom_3d_gaussian_filter(filter_half_width)\n",
    "\n",
    "        if bin_factor_dilatation > 1:\n",
    "            data_smoothed = fast_pytorch_bin_3d(data,bin_factor_dilatation, chunk_size = 71)\n",
    "        else:\n",
    "            data_smoothed = data\n",
    "\n",
    "        print('\\t3D smoothing for thresholding of mask_solid and mask_needle:')\n",
    "        data_smoothed = apply_3d_image_processing_on_subvolumes(data_smoothed, fast_pytorch_convolution, kernel_array = kernel, chunk_size_max = (500, 500, 500), overlap = 3*filter_half_width)\n",
    "\n",
    "        if bin_factor_dilatation > 1:\n",
    "            data_smoothed = skimage.transform.rescale(data_smoothed, bin_factor_dilatation, multichannel=False)\n",
    "\n",
    "        mask_needle = data_smoothed > threshold_needle\n",
    "        mask_needle = apply_3d_image_processing_on_subvolumes(mask_needle, fast_pytorch_mask_dilation, chunk_size_max = (500, 500, 500), overlap = mask_growth_needle, radius = mask_growth_needle)\n",
    "\n",
    "        mask_solid = data_smoothed > threshold\n",
    "        mask_solid[mask_needle] = False\n",
    "\n",
    "        for ind, slice in enumerate(mask_solid):\n",
    "            slice[~mask_enclosing_circle] = False\n",
    "            mask_solid[ind] = slice\n",
    "\n",
    "        print('\\tSaving mask_solid and mask_needle:')\n",
    "        File(this_scan.full_path+'/b_movingRegisteredToStatic_maskNeedle').saveTiffStack(mask_needle, type = 'bool')\n",
    "        File(this_scan.full_path+'/b_movingRegisteredToStatic_maskSolid').saveTiffStack(mask_solid, type = 'bool')\n",
    "    else:\n",
    "        print('\\tRe-loading mask solid and mask needle')\n",
    "        mask_solid = File(this_scan.full_path+'/b_movingRegisteredToStatic_maskSolid').readAll()\n",
    "        mask_needle = File(this_scan.full_path+'/b_movingRegisteredToStatic_maskNeedle').readAll()\n",
    "\n",
    "    return(mask_solid.astype('bool'), mask_needle.astype('bool'))\n",
    "\n",
    "def compute_height(properties):\n",
    "    for prop in properties:\n",
    "        bbox = prop.bbox\n",
    "        prop.height = bbox[3]-bbox[0] # Along z, in pixels\n",
    "    return(properties)\n",
    "\n",
    "def compute_equivalent_cylinder_diameters(properties):\n",
    "    for prop in properties:\n",
    "        equivalent_cylinder_cross_section = prop.area / prop.height\n",
    "        prop.equivalent_cylinder_diameter = np.sqrt(4*equivalent_cylinder_cross_section/np.pi) * voxel_size\n",
    "    return(properties)\n",
    "\n",
    "def get_path_length(graph, path):\n",
    "    this_sum=0\n",
    "    for i in range(len(path)-1):\n",
    "        this_sum += graph.get_edge_data(path[i], path[i+1])['weight']\n",
    "    return(this_sum)\n",
    "\n",
    "def longest_simple_path(graph, source, target):\n",
    "    longest_path = None\n",
    "    longest_path_length = 0\n",
    "    for path in nx.all_simple_paths(graph, source=source, target=target):\n",
    "        path_length = get_path_length(graph,path)\n",
    "        if path_length > longest_path_length:\n",
    "            longest_path_length = path_length\n",
    "            longest_path = path\n",
    "    return longest_path, longest_path_length\n",
    "\n",
    "def find_longest_subgraph_from_ends(graph, bbox):\n",
    "\n",
    "    ind_end_nodes = [x for x in graph.nodes if graph.degree(x) == 1]\n",
    "    ind_end_bottom = [x for x in ind_end_nodes if graph.nodes[x]['o'][0] - bbox[0] <=  bbox[3] - graph.nodes[x]['o'][0]]\n",
    "    ind_end_top = [x for x in ind_end_nodes if not x in ind_end_bottom]\n",
    "\n",
    "    longest_path_subgraph = None\n",
    "    longest_path_length = 0\n",
    "    longest_path = []\n",
    "    for ind_bot in ind_end_bottom:\n",
    "        for ind_top in ind_end_top:\n",
    "            this_longest_path, this_longest_path_length = longest_simple_path(graph, source=ind_bot, target=ind_top)\n",
    "            this_longest_path_subgraph = graph.subgraph(this_longest_path)\n",
    "\n",
    "            if this_longest_path_length > longest_path_length:\n",
    "                longest_path_length = this_longest_path_length\n",
    "                longest_path = this_longest_path\n",
    "                longest_path_subgraph = this_longest_path_subgraph\n",
    "\n",
    "    return(longest_path_subgraph, longest_path, longest_path_length)\n",
    "\n",
    "def compute_tortuosity(skeleton_properties):\n",
    "\n",
    "    for ind_pore in range(len(skeleton_properties)):\n",
    "        bbox = skeleton_properties[ind_pore].bbox\n",
    "        graph = sknw.build_sknw(skeleton_properties[ind_pore].image, multi=False, iso=False, ring=False, full=True)\n",
    "        longest_path_subgraph, longest_path, longest_path_length = find_longest_subgraph_from_ends(graph, bbox)\n",
    "\n",
    "        if longest_path_length == 0:\n",
    "            longest_path_length = np.nan\n",
    "\n",
    "        skeleton_properties[ind_pore].length_skeleton = longest_path_length\n",
    "        skeleton_properties[ind_pore].longest_path = longest_path\n",
    "        # skeleton_properties[ind_pore].longest_path_subgraph = longest_path_subgraph\n",
    "        skeleton_properties[ind_pore].tortuosity = longest_path_length / skeleton_properties[ind_pore].height\n",
    "\n",
    "        # print(ind_pore, longest_path_length, skeleton_properties[ind_pore].tortuosity)\n",
    "    return(skeleton_properties)\n",
    "\n",
    "def compute_skeleton(this_scan, mask_pores, force_redo = False):\n",
    "\n",
    "    if force_redo or not 'b_movingRegisteredToStatic_maskPores_skeleton' in os.listdir(this_scan.full_path):\n",
    "        skeleton = skeletonize(mask_pores)\n",
    "        File(this_scan.full_path+'/b_movingRegisteredToStatic_maskPores_skeleton').saveTiffStack(skeleton, type = 'bool')\n",
    "    else:\n",
    "        print('\\tRe-loading skeleton')\n",
    "        skeleton = File(this_scan.full_path+'/b_movingRegisteredToStatic_maskPores_skeleton').readAll()\n",
    "    return(skeleton)\n",
    "\n",
    "def find_top_bottom_slices_ind(this_scan, mask_solid, ind_all_top, ind_all_bottom):\n",
    "\n",
    "    this_scan.ind_all_margin = 100\n",
    "    this_scan.ind_margin = 30\n",
    "    this_scan.relative_porosity_threshold = 0.15\n",
    "\n",
    "    mask_solid_slice_sum = np.sum(np.sum(mask_solid, axis = 2), axis = 1)\n",
    "    mean_area_ind_all = np.mean(mask_solid_slice_sum[ind_all_top+this_scan.ind_all_margin:ind_all_bottom-this_scan.ind_all_margin])\n",
    "\n",
    "    this_scan.relative_porosity = np.abs(mean_area_ind_all-mask_solid_slice_sum)/mean_area_ind_all\n",
    "\n",
    "    this_scan.ind_top = np.min(np.where(this_scan.relative_porosity<this_scan.relative_porosity_threshold)) + this_scan.ind_margin\n",
    "    this_scan.ind_bottom = np.max(np.where(this_scan.relative_porosity<this_scan.relative_porosity_threshold)) - this_scan.ind_margin\n",
    "\n",
    "    this_scan.height_ROI = this_scan.ind_bottom-this_scan.ind_top + 1\n",
    "\n",
    "    print('\\t\\tDetected ROI:\\tind_top: '+str(this_scan.ind_top)+', ind_bottom: '+str(this_scan.ind_bottom)+', height: '+str(this_scan.height_ROI))\n",
    "    if (this_scan.height_ROI < 200):\n",
    "        print('\\t\\t\\t\\t/!\\ WARNING: small height of ROI detected: check the cropping of mask solid')\n",
    "\n",
    "    return(this_scan)\n",
    "\n",
    "def mask_crop_ROI(mask, ind_top, ind_bottom):\n",
    "    mask[:ind_top] = False\n",
    "    mask[ind_bottom:] = False\n",
    "    return(mask)\n",
    "\n",
    "def close_mask_solid(this_scan, mask_solid, mask_needle, force_redo = False):\n",
    "\n",
    "    if force_redo or not 'b_movingRegisteredToStatic_maskSolidClosed' in os.listdir(this_scan.full_path):\n",
    "\n",
    "        # Option #1: Morphological closing to close the pores\n",
    "        # chunk_size = (500, 500, 500)\n",
    "        # filter_half_width = 12\n",
    "        # structure = custom_3d_kernel_sphere(filter_half_width)\n",
    "        # mask_solid_dilated = apply_3d_image_processing_on_subvolumes(mask_solid, fast_pytorch_mask_dilation, chunk_size_max = chunk_size, overlap = filter_half_width, radius = filter_half_width)\n",
    "        # mask_solid_closed = ~apply_3d_image_processing_on_subvolumes(~mask_solid_dilated, fast_pytorch_mask_dilation, chunk_size_max = chunk_size, overlap = filter_half_width, radius = filter_half_width)\n",
    "\n",
    "        # Option #2: Fill holes algorithm run slice by slice\n",
    "        n_threads = 16\n",
    "        mask_solid_closed = np.zeros_like(mask_solid)\n",
    "        with multiprocessing.Pool(n_threads) as p:\n",
    "            mask_solid_closed = np.array(p.map(scipy.ndimage.morphology.binary_fill_holes, mask_solid))\n",
    "\n",
    "        # 1 core version of option #2\n",
    "        # for ind, slice in enumerate(mask_solid):\n",
    "        #     mask_solid_closed[ind] = scipy.ndimage.morphology.binary_fill_holes(slice)\n",
    "        #     print(ind)\n",
    "\n",
    "        mask_solid_closed[mask_needle] = False\n",
    "        File(this_scan.full_path+'/b_movingRegisteredToStatic_maskSolidClosed').saveTiffStack(mask_solid_closed, type = 'bool')\n",
    "    else:\n",
    "        print('\\tRe-loading mask solid closed')\n",
    "        mask_solid_closed = File(this_scan.full_path+'/b_movingRegisteredToStatic_maskSolidClosed').readAll()\n",
    "\n",
    "    return(mask_solid_closed.astype('bool'))\n",
    "\n",
    "def rotate_data(data, rot_coronal_Fiji, rot_sagittal_Fiji, rot_z_Fiji = 0.0):\n",
    "    pad = 1\n",
    "    transform_rotation = sitk.Euler3DTransform()\n",
    "    center_xyz = (data.shape[0] / 2.0+pad, data.shape[1] / 2.0+pad, data.shape[2] / 2.0+pad) # TODO: Is this correct? Not consistent with below\n",
    "    center_angle = 0.0\n",
    "    offsets_xyz = (0.0, 0.0, 0.0)\n",
    "\n",
    "    transform_rotation.SetFixedParameters((center_xyz[0], center_xyz[1], center_xyz[2], center_angle))\n",
    "    eulerAngle_xyz_deg = (-rot_sagittal_Fiji, rot_coronal_Fiji, 0.0)\n",
    "    transform_rotation.SetParameters((eulerAngle_xyz_deg[0]/180.0*np.pi, eulerAngle_xyz_deg[1]/180.0*np.pi, eulerAngle_xyz_deg[2]/180.0*np.pi, offsets_xyz[0], offsets_xyz[1], offsets_xyz[2]))\n",
    "\n",
    "    data_bigger = np.zeros([data.shape[0]+pad*2, data.shape[1]+pad*2, data.shape[2]+pad*2])\n",
    "    data_bigger[pad:-pad, pad:-pad, pad:-pad] = data\n",
    "    data_out = applyTransformToVolume(data_bigger, data_bigger, transform_rotation)\n",
    "\n",
    "    # Then only axial rotation. Can't do all axis at once to match Fiji\n",
    "    if rot_z_Fiji != 0:\n",
    "        center_xyz = (data_out.shape[2] / 2.0, data_out.shape[1] / 2.0, data_out.shape[0] / 2.0)\n",
    "        transform_rotation.SetFixedParameters((center_xyz[0], center_xyz[1], center_xyz[2], center_angle))\n",
    "        eulerAngle_xyz_deg = (0.0, 0.0, -rot_z_Fiji)\n",
    "        offsets_xyz2 = (0.0, -50.0, 0.0)\n",
    "        transform_rotation.SetParameters((eulerAngle_xyz_deg[0]/180.0*np.pi, eulerAngle_xyz_deg[1]/180.0*np.pi, eulerAngle_xyz_deg[2]/180.0*np.pi, offsets_xyz2[0], offsets_xyz2[1], offsets_xyz2[2]))\n",
    "        data_out2 = applyTransformToVolume(data_out, data_out, transform_rotation)\n",
    "    else:\n",
    "        data_out2 = data_out\n",
    "\n",
    "    return(data_out2[pad:-pad, pad:-pad, pad:-pad])\n",
    "\n",
    "def analyze_pores_2d(this_scan, mask_pores):\n",
    "    tic = time.time()\n",
    "\n",
    "    this_scan.slice_angles_to_growth = []\n",
    "    this_scan.slice_ellipse_major_diameters = []\n",
    "    this_scan.slice_ellipse_minor_diameters = []\n",
    "    this_scan.slice_ellipse_eccentricity = []\n",
    "    this_scan.slice_areas = []\n",
    "    this_scan.slice_eq_diameters = []\n",
    "    this_scan.slice_perimeters = []\n",
    "\n",
    "    for ind, slice in enumerate(mask_pores):\n",
    "        slice_lab = measure.label(slice)\n",
    "        slice_properties = np.array(measure.regionprops(slice_lab))\n",
    "\n",
    "         # Angle w.r.t vertical (growth axis), with positive being CCW, in degrees, from -90 to 90\n",
    "        angles = 180 / np.pi * np.array([p.orientation for p in slice_properties]) # From -90 to 90\n",
    "        # angles[angles<0] = 180+angles[angles<0]\n",
    "        this_scan.slice_angles_to_growth.append(angles)\n",
    "\n",
    "        this_scan.slice_ellipse_major_diameters.append(np.array([p.axis_major_length for p in slice_properties]))\n",
    "        this_scan.slice_ellipse_minor_diameters.append(np.array([p.axis_minor_length for p in slice_properties]))\n",
    "        this_scan.slice_ellipse_eccentricity.append(np.array([p.eccentricity for p in slice_properties]))\n",
    "        this_scan.slice_eq_diameters.append(np.array([p.equivalent_diameter_area for p in slice_properties]))\n",
    "        this_scan.slice_perimeters.append(np.array([p.perimeter for p in slice_properties]))\n",
    "        this_scan.slice_areas.append(np.array([p.area for p in slice_properties]))\n",
    "\n",
    "        if ind % 100 == 0:\n",
    "            print('.', end='')\n",
    "\n",
    "    return(this_scan)\n",
    "\n",
    "def meanAttenuationVolume(this_scan, mask_to_use, data): \n",
    "    mu_s = np.nanmean(data[mask_to_use])\n",
    "    V_s = np.nansum(mask_to_use.flatten())*(voxel_size*10**-6)**3 #[m]\n",
    "    return(mu_s,V_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Parameters - Run 21 (Oak, low heat)\n"
    }
   },
   "outputs": [],
   "source": [
    "# Rotation\n",
    "rot_coronal_Fiji = np.nan # [Deg]\n",
    "rot_sagittal_Fiji = np.nan # [Deg]\n",
    "rot_z_Fiji = np.nan # [Deg] This angle: such that tree growth is vertical from bottom to top in Fiji, after sagittal / coronal rotation\n",
    "\n",
    "# Top and bottom indices along z that contain sample for all scans (after rotation /!\\)\n",
    "ind_all_top = np.nan\n",
    "ind_all_bottom = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Parameters - Run 23 (Walnut, low heat)\n"
    }
   },
   "outputs": [],
   "source": [
    "# Rotation\n",
    "rot_coronal_Fiji = np.nan # [Deg]\n",
    "rot_sagittal_Fiji = np.nan # [Deg]\n",
    "rot_z_Fiji = np.nan # [Deg] This angle: such that tree growth is vertical from bottom to top in Fiji, after sagittal / coronal rotation\n",
    "\n",
    "# Top and bottom indices along z that contain sample for all scans (after rotation /!\\)\n",
    "ind_all_top = np.nan\n",
    "ind_all_bottom = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Parameters - Run 24 (Birch, low heat)\n"
    }
   },
   "outputs": [],
   "source": [
    "# Rotation\n",
    "rot_coronal_Fiji = -1.0 # [Deg]\n",
    "rot_sagittal_Fiji = -5.0 # [Deg]\n",
    "rot_z_Fiji = -91.5 # [Deg] This angle: such that tree growth is vertical from bottom to top in Fiji, after sagittal / coronal rotation\n",
    "\n",
    "# Top and bottom indices along z that contain sample for all scans (after rotation /!\\)\n",
    "ind_all_top = 130\n",
    "ind_all_bottom = 465\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Parameters - Run 26 (Birch, high heat)\n"
    }
   },
   "outputs": [],
   "source": [
    "# Rotation\n",
    "rot_coronal_Fiji = -0.2 # [Deg]\n",
    "rot_sagittal_Fiji = 0.5 # [Deg]\n",
    "rot_z_Fiji = 40.0 # [Deg] This angle: such that tree growth is vertical from bottom to top in Fiji, after sagittal / coronal rotation\n",
    "\n",
    "# Top and bottom indices along z that contain sample for all scans (after rotation /!\\)\n",
    "ind_all_top = np.nan\n",
    "ind_all_bottom = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Check list\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running scan #1 - 01\n"
     ]
    }
   ],
   "source": [
    "ind_scan = 0\n",
    "this_scan = list_scans[ind_scan]\n",
    "print('Running scan #'+str(ind_scan+1)+' - '+this_scan.folder_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Main loop: run over all scans\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running scan #1/37 - 01\n",
      "\tLoading data took: 5.895115613937378\n",
      "\tRotating data took: 10.268530368804932\n",
      "\t3D smoothing for thresholding of mask_solid and mask_needle:\n",
      "\t Processing 18 chunks of size [349 426 426] .................. Done\n",
      "\t Processing 18 chunks of size [349 426 426] ........."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27151/2213131950.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Computing mask solid and mask needle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mmask_solid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_needle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_mask_solid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_scan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_redo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforce_redo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Crop mask solid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_27151/4062825999.py\u001b[0m in \u001b[0;36mcompute_mask_solid\u001b[0;34m(this_scan, data, force_redo)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mmask_needle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_smoothed\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold_needle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mmask_needle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_3d_image_processing_on_subvolumes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_needle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfast_pytorch_mask_dilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_growth_needle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_growth_needle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mmask_solid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_smoothed\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/cfs/cdirs/als/users/eboigne/cfoster/code/als6/tomoTools_als832/tomoTools/scripts.py\u001b[0m in \u001b[0;36mapply_3d_image_processing_on_subvolumes\u001b[0;34m(vol, fct, chunk_size_max, padding, overlap, bool_try_smaller_chunks, *args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0;31m# Apply function to subvolume\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0msub_vol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_vol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0;31m# Remove padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/cfs/cdirs/als/users/eboigne/cfoster/code/als6/tomoTools_als832/tomoTools/scripts.py\u001b[0m in \u001b[0;36mfast_pytorch_mask_dilation\u001b[0;34m(mask, radius, use_pyTorch)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_3d_kernel_sphere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_pyTorch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmask_grown\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_pytorch_convolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# cpu, lot slower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mmask_grown\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_dilation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/cfs/cdirs/als/users/eboigne/cfoster/code/als6/tomoTools_als832/tomoTools/scripts.py\u001b[0m in \u001b[0;36mfast_pytorch_convolution\u001b[0;34m(img, kernel_array, verbose, chunk_size)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\tCuda to Numpy (convolution) took: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' s'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Re-load scan data\n",
    "# with open(path_save+case+'/post_pro_data.pickle', 'rb') as handle:\n",
    "#     list_scans = pickle.load(handle)\n",
    "\n",
    "nb_scans = len(list_scans)\n",
    "force_redo = True\n",
    "\n",
    "for ind_scan,this_scan in enumerate(list_scans[:1]):\n",
    "    tic_scan = time.time()\n",
    "\n",
    "    print('Running scan #'+str(ind_scan+1)+'/'+str(nb_scans)+' - '+this_scan.folder_name)\n",
    "\n",
    "    # Loading data\n",
    "    tic = time.time()\n",
    "    data = File(path_save+case+'/'+this_scan.folder_name+'/b_movingRegisteredToStatic/').readAll()\n",
    "    print('\\tLoading data took: '+str(time.time()-tic))\n",
    "\n",
    "    # Rotating data\n",
    "    tic = time.time()\n",
    "    data = rotate_data(data, rot_coronal_Fiji, rot_sagittal_Fiji, rot_z_Fiji)\n",
    "    print('\\tRotating data took: '+str(time.time()-tic))\n",
    "    File(path_save+case+'/'+this_scan.folder_name+'/b_movingRegisteredToStatic_rotatedZ/').saveTiff(data[data.shape[0]//2-100,:,:], ind=0)\n",
    "    File(path_save+case+'/'+this_scan.folder_name+'/b_movingRegisteredToStatic_rotatedZ/').saveTiff(data[data.shape[0]//2,:,:], ind=1)\n",
    "    File(path_save+case+'/'+this_scan.folder_name+'/b_movingRegisteredToStatic_rotatedZ/').saveTiff(data[data.shape[0]//2+100,:,:], ind=2)\n",
    "    File(path_save+case+'/'+this_scan.folder_name+'/b_movingRegisteredToStatic_rotatedXY/').saveTiff(data[:,data.shape[1]//2,:], ind=0)\n",
    "    File(path_save+case+'/'+this_scan.folder_name+'/b_movingRegisteredToStatic_rotatedXY/').saveTiff(data[:,:,data.shape[2]//2], ind=1)\n",
    "\n",
    "    # Computing mask solid and mask needle\n",
    "    mask_solid, mask_needle = compute_mask_solid(this_scan, data, force_redo = force_redo)\n",
    "\n",
    "    # Crop mask solid\n",
    "    this_scan = find_top_bottom_slices_ind(this_scan, mask_solid, ind_all_top, ind_all_bottom)\n",
    "    mask_solid = mask_crop_ROI(mask_solid, this_scan.ind_top, this_scan.ind_bottom)\n",
    "\n",
    "    # Close mask_solid and compute porosity\n",
    "    print('\\tClosing mask solid')\n",
    "    mask_solid_closed = close_mask_solid(this_scan, mask_solid, mask_needle, force_redo = force_redo)\n",
    "    this_scan.porosity = 1 - np.sum(mask_solid.flatten()) / np.sum(mask_solid_closed.flatten())\n",
    "\n",
    "    # Analyze pore structure (3D)\n",
    "    mask_pores = mask_solid_closed * (~mask_solid)\n",
    "    tic = time.time()\n",
    "    lab = measure.label(mask_pores)\n",
    "    properties = np.array(measure.regionprops(lab))\n",
    "    print('\\tParticle identification and analysis took: '+str(time.time()-tic))\n",
    "\n",
    "    # Cleaning up pores (3D)\n",
    "    properties = compute_height(properties)\n",
    "    areas = np.array([prop.area for prop in properties])\n",
    "    height = np.array([prop.height for prop in properties])\n",
    "    this_scan.ind_properties_cleaned = np.where((areas>500) * (areas < 300000) * (height > 100))[0]\n",
    "    properties_cleaned = properties[this_scan.ind_properties_cleaned]\n",
    "\n",
    "    # Compute equivalent cylinder diameters (3D)\n",
    "    properties_cleaned = compute_equivalent_cylinder_diameters(properties_cleaned)\n",
    "    this_scan.nb_pores = len(properties_cleaned)\n",
    "    # this_scan.pore_properties = properties_cleaned # Don't save this, otherwise pickle too heavy (image data stored)\n",
    "\n",
    "    # Analyze pore structure (2D, slice by slice)\n",
    "    print('\\tStarting 2D pore analysis ', end ='')\n",
    "    tic = time.time()\n",
    "    this_scan = analyze_pores_2d(this_scan, mask_pores)\n",
    "    print(' Done, it took: '+str(time.time()-tic))\n",
    "\n",
    "    # Build and analyze skeleton for tortuosity\n",
    "    tic = time.time()\n",
    "    skeleton = compute_skeleton(this_scan, mask_pores, force_redo = force_redo)\n",
    "    skeleton_lab = measure.label(skeleton)\n",
    "    skeleton_properties = measure.regionprops(skeleton_lab)\n",
    "    print('\\tSkeletonize and analysis took: '+str(time.time()-tic))\n",
    "\n",
    "    # Extract which pores to keep from skeleton\n",
    "    skeleton_properties = compute_height(skeleton_properties)\n",
    "    skeleton_areas = np.array([prop.area for prop in skeleton_properties])\n",
    "    skeleton_height = np.array([prop.height for prop in skeleton_properties])\n",
    "    this_scan.skeleton_ind_properties_cleaned = np.where((skeleton_areas>50) * (skeleton_areas < 1000) * (skeleton_height > 100))[0]\n",
    "\n",
    "    # Compute tortuosity for each pore\n",
    "    skeleton_properties_cleaned = compute_tortuosity(np.array(skeleton_properties)[this_scan.skeleton_ind_properties_cleaned])\n",
    "\n",
    "    # Compute mean solid attenuation and solid volume\n",
    "    this_scan.mu_solid_open, this_scan.volume_solid_open = meanAttenuationVolume(this_scan, mask_solid, data)\n",
    "    this_scan.mu_solid_closed, this_scan.volume_solid_closed = meanAttenuationVolume(this_scan, mask_solid_closed, data)\n",
    "\n",
    "    # Save relevant pore & skeleton properties\n",
    "    this_scan.areas = [prop.area for prop in properties_cleaned]\n",
    "    this_scan.equivalent_cylinder_diameters = [prop.equivalent_cylinder_diameter for prop in properties_cleaned]\n",
    "    this_scan.heights = [prop.height for prop in properties_cleaned]\n",
    "    this_scan.skeleton_pore_path_length = [prop.length_skeleton for prop in skeleton_properties_cleaned]\n",
    "    this_scan.tortuosity = [prop.tortuosity for prop in skeleton_properties_cleaned if not np.isnan(prop.tortuosity) and prop.tortuosity > 1]\n",
    "\n",
    "    # Update save of scan data\n",
    "    print('\\tUpdating save pickle')\n",
    "    with open(path_save+case+'/post_pro_data.pickle', 'wb') as handle:\n",
    "        pickle.dump(list_scans, handle)\n",
    "\n",
    "    print('\\tThis scan took: '+str(time.time()-tic_scan))\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Load scan data\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(path_save+case+'/post_pro_data.pickle', 'rb') as handle:\n",
    "    list_scans = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "34\n",
      "21a\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Data' object has no attribute 'porosity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_114346/304800686.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_scans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind_scan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_scans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind_scan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_scans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind_scan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mporosity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_scans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind_scan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_pores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Data' object has no attribute 'porosity'"
     ]
    }
   ],
   "source": [
    "print(len(list_scans))\n",
    "\n",
    "ind_scan = 34\n",
    "\n",
    "print(list_scans[ind_scan].ind)\n",
    "print(list_scans[ind_scan].folder_name)\n",
    "print(list_scans[ind_scan].porosity)\n",
    "print(list_scans[ind_scan].nb_pores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Export vertical slices\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading scan #1/52 - 21a\n",
      "\tLoading data took: 29.47336220741272\n",
      "Loading scan #2/52 - 21b\n",
      "\tLoading data took: 28.624576807022095\n",
      "Loading scan #3/52 - 22a\n",
      "\tLoading data took: 29.96585750579834\n",
      "Loading scan #4/52 - 22b\n",
      "\tLoading data took: 28.03941583633423\n",
      "Loading scan #5/52 - 23a\n",
      "\tLoading data took: 26.810391426086426\n",
      "Loading scan #6/52 - 23b\n",
      "\tLoading data took: 28.192319869995117\n",
      "Loading scan #7/52 - 24a\n",
      "\tLoading data took: 28.19716763496399\n",
      "Loading scan #8/52 - 24b\n",
      "\tLoading data took: 27.833656787872314\n",
      "Loading scan #9/52 - 25a\n",
      "\tLoading data took: 27.228797912597656\n",
      "Loading scan #10/52 - 25b\n",
      "\tLoading data took: 27.412358283996582\n",
      "Loading scan #11/52 - 26a\n",
      "\tLoading data took: 27.326425313949585\n",
      "Loading scan #12/52 - 26b\n",
      "\tLoading data took: 26.930753707885742\n",
      "Loading scan #13/52 - 27-post\n",
      "\tLoading data took: 26.810258865356445\n",
      "Loading scan #14/52 - 28-post\n",
      "\tLoading data took: 28.123441219329834\n",
      "Loading scan #15/52 - 29-post\n",
      "\tLoading data took: 27.962918519973755\n",
      "Loading scan #16/52 - 30-post\n",
      "\tLoading data took: 27.8821918964386\n",
      "Loading scan #17/52 - 31-post\n",
      "\tLoading data took: 28.901204586029053\n",
      "Loading scan #18/52 - 32-post\n",
      "\tLoading data took: 28.715858459472656\n"
     ]
    }
   ],
   "source": [
    "ind_slice_X = 600-1 # Reslice from Top in Fiji\n",
    "ind_slice_Y = 620-1 # Reslice from Left in Fiji\n",
    "nb_scans = len(list_scans)\n",
    "\n",
    "for ind_scan,this_scan in enumerate(list_scans[34:]):\n",
    "\n",
    "    print('Loading scan #'+str(ind_scan+1)+'/'+str(nb_scans)+' - '+this_scan.folder_name)\n",
    "\n",
    "    # Loading data\n",
    "    tic = time.time()\n",
    "    data = File(path_save+case+'/'+this_scan.folder_name+'/b_movingRegisteredToStatic/').readAll()\n",
    "    print('\\tLoading data took: '+str(time.time()-tic))\n",
    "\n",
    "    File(path_save+case+'/probe_sliceX_'+str(ind_slice_X).zfill(4)).saveTiff(data[:,ind_slice_X,:], ind = this_scan.ind)\n",
    "    File(path_save+case+'/probe_sliceY_'+str(ind_slice_Y).zfill(4)).saveTiff(data[:,:,ind_slice_Y], ind = this_scan.ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a1b0112286f7c446d5292efd04793b678edb2622b6f6ca41624bb41affddd0cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
